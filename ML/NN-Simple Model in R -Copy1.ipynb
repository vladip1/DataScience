{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks\n",
    " \n",
    "Today we will build a neural network (NN) from scratch. \n",
    "\n",
    "The structure of the NN is shown in the following image:\n",
    "  \n",
    "<img src=\"https://i1.wp.com/res.cloudinary.com/dxqnb8xjb/image/upload/v1539018324/nn_diagram_d7gs7e.png?w=456&ssl=1\" />\n",
    " \n",
    " \n",
    "This NN have three layers: \n",
    "\n",
    "- Input layer: this layer is constitute the input data\n",
    "- Hidden layer: this is the most internal layer. This layer is not visible to the user that is why NN are considered black boxes. \n",
    "- Output layer: this layer will contain our output ($\\hat{y}$)\n",
    "\n",
    "\n",
    "<img src=\"https://cdnpythonmachinelearning.azureedge.net/wp-content/uploads/2017/09/Single-Perceptron.png?x31195\" width=\"600\" height=\"400\" />\n",
    " \n",
    " \n",
    "We proceed with the input layer and calculate the weights and the bias for each of the input (X's):\n",
    " \n",
    "$$ z = W_{i1}^{T}X + b_1 $$\n",
    "\n",
    "This is called the <b> Transfer Function </b>. After that, the resulting vector (z) is passed through an <b> Activation Function </b>. There are many types of activation functions, one of them we yet know, the <b>sigmoid function </b>:\n",
    " \n",
    "$$   \\sigma = 1 / (1 + exp^{-z})  $$\n",
    "\n",
    "Lets code this functions:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#' the activation function\n",
    "sigmoid <- function(x) {\n",
    "  1.0 / (1.0 + exp(-x))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feedforward\n",
    " \n",
    "The transfer and activation functions are applyed to the first layer (input layer) and the resuts are passed to the following layer (hidden layer) and both functions are now applied to it. Then the reult is passed to the output layer. Those passes are known as feedforward step. Now we will define this function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Feedforward\n",
    "feedforward <- function(nn) {\n",
    "  ## activation of the first layer\n",
    "  nn$layer1 <- sigmoid(nn$input %*% nn$weights1)\n",
    "  ## activation of the following layer\n",
    "  nn$output <- sigmoid(nn$layer1 %*% nn$weights2)\n",
    "  return(nn)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end, the final feedforward function for our network looks as follows:\n",
    " \n",
    "$$ \\hat{y} = \\sigma(W_2^{T}(\\sigma(W_1^{T}X) + b_1) + b_2 )  $$\n",
    " \n",
    "\n",
    "## Backpropagation\n",
    " \n",
    "The resulting output of the feedforward step gives a result that has a high error (loss). To reduce this error, the weight and bias are corrected by going backwards. This step is known as backpropagation. This is done by the following function:\n",
    " \n",
    "$$  2(y - \\hat{y}) * z(1-z) * X $$\n",
    " \n",
    "where z is\n",
    "\n",
    "$$  z = (W^{T}X + b) $$\n",
    "\n",
    "and $ z(1-z) $ is known as the <b>derivative of the sigmoid function</b>.\n",
    "\n",
    "Now we add the code for the backpropagation function:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#' the derivative of the activation function\n",
    "sigmoid_derivative <- function(x) {\n",
    "  return(x * (1.0 - x))\n",
    "}\n",
    "\n",
    "## Backpropagation\n",
    "backprop <- function(nn) {\n",
    "  # application of the chain rule to find derivative of the loss function with \n",
    "  # respect to weights2 and weights1\n",
    "    \n",
    "  # `2 * (nn$y - nn$output)` is the derivative of the sigmoid loss function\n",
    "  d_weights2 <- ( t(nn$layer1) %*% (2 * (nn$y - nn$output) * sigmoid_derivative(nn$output)) )\n",
    "\n",
    "  d_weights1 <- ( 2 * (nn$y - nn$output) * sigmoid_derivative(nn$output)) %*% t(nn$weights2)\n",
    "    \n",
    "  d_weights1 <- d_weights1 * sigmoid_derivative(nn$layer1)\n",
    "    \n",
    "  d_weights1 <- t(nn$input) %*% d_weights1\n",
    "  \n",
    "  # update the weights using the derivative (slope) of the loss function\n",
    "  nn$weights1 <- nn$weights1 + d_weights1\n",
    "  nn$weights2 <- nn$weights2 + d_weights2\n",
    "\n",
    "  return(nn)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function\n",
    " \n",
    "Now that we have all the needed functions for our NN, we have to define the loss function. We will use the Sum of Squared Error: \n",
    "\n",
    "$$  cost = \\sum_{i=1}^{n} {(y - \\hat{y})^{2}} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loss function: SSE\n",
    "loss_function <- function(nn) {\n",
    "  return(sum((nn$y - nn$output) ^ 2))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And  we define the gradient descent function by running the network (feed)fordward and backward (backpropagation) while recalculating the loss function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "GD <- function(nnet, num_iter=100) {\n",
    "    n <- num_iter\n",
    "\n",
    "    # data frame to store the results of the loss function.\n",
    "    # this data frame is used to produce the plot in the \n",
    "    # next code chunk\n",
    "    loss_df <- data.frame(iteration = 1:n+1, loss = vector(\"numeric\", length = n) )\n",
    "\n",
    "    for (i in seq_len(num_iter)) {\n",
    "      nnet <- feedforward(nnet)\n",
    "      nnet <- backprop(nnet)\n",
    "\n",
    "      # store the result of the loss function.  We will plot this later\n",
    "      loss_df$loss[i] <- loss_function(nnet)\n",
    "    }\n",
    "    # print the predicted outcome next to the actual outcome\n",
    "    yhat <- data.frame(\"Predicted\" = round(nnet$output, 3), \"Actual\" = y)\n",
    "    res <- list(yhat=yhat, loss=loss_df)\n",
    "    return(res)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "NeuralNetwork <- function(X, y, num_nodes, num_iter=100) {\n",
    "    # generate a random value between 0 and 1 for each\n",
    "    # element in X.  This will be used as our initial weights\n",
    "    # for layer 1\n",
    "    rand_vector <- runif(ncol(X) * nrow(X))\n",
    "\n",
    "    # convert above vector into a matrix\n",
    "    rand_matrix <- matrix(rand_vector, nrow = ncol(X), ncol = nrow(X), byrow = TRUE)\n",
    "\n",
    "    # this list stores the state of our neural net as it is trained\n",
    "    nnet <- list(input = X,                              # predictor variables\n",
    "                  weights1 = rand_matrix,                 # weights for layer 1\n",
    "                  weights2 = matrix(runif(num_nodes), ncol = 1),  # weights for layer 2\n",
    "                  y = y,                                  # actual observed\n",
    "                  output = matrix(rep(0, times = num_nodes), ncol = 1)   # stores the predicted outcome\n",
    "                 )\n",
    "    return(GD(nnet, num_iter))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.frame: 6 × 11</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>mpg</th><th scope=col>cyl</th><th scope=col>disp</th><th scope=col>hp</th><th scope=col>drat</th><th scope=col>wt</th><th scope=col>qsec</th><th scope=col>vs</th><th scope=col>am</th><th scope=col>gear</th><th scope=col>carb</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>Mazda RX4</th><td>21.0</td><td>6</td><td>160</td><td>110</td><td>3.90</td><td>2.620</td><td>16.46</td><td>0</td><td>1</td><td>4</td><td>4</td></tr>\n",
       "\t<tr><th scope=row>Mazda RX4 Wag</th><td>21.0</td><td>6</td><td>160</td><td>110</td><td>3.90</td><td>2.875</td><td>17.02</td><td>0</td><td>1</td><td>4</td><td>4</td></tr>\n",
       "\t<tr><th scope=row>Datsun 710</th><td>22.8</td><td>4</td><td>108</td><td> 93</td><td>3.85</td><td>2.320</td><td>18.61</td><td>1</td><td>1</td><td>4</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>Hornet 4 Drive</th><td>21.4</td><td>6</td><td>258</td><td>110</td><td>3.08</td><td>3.215</td><td>19.44</td><td>1</td><td>0</td><td>3</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>Hornet Sportabout</th><td>18.7</td><td>8</td><td>360</td><td>175</td><td>3.15</td><td>3.440</td><td>17.02</td><td>0</td><td>0</td><td>3</td><td>2</td></tr>\n",
       "\t<tr><th scope=row>Valiant</th><td>18.1</td><td>6</td><td>225</td><td>105</td><td>2.76</td><td>3.460</td><td>20.22</td><td>1</td><td>0</td><td>3</td><td>1</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 11\n",
       "\\begin{tabular}{r|lllllllllll}\n",
       "  & mpg & cyl & disp & hp & drat & wt & qsec & vs & am & gear & carb\\\\\n",
       "  & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\tMazda RX4 & 21.0 & 6 & 160 & 110 & 3.90 & 2.620 & 16.46 & 0 & 1 & 4 & 4\\\\\n",
       "\tMazda RX4 Wag & 21.0 & 6 & 160 & 110 & 3.90 & 2.875 & 17.02 & 0 & 1 & 4 & 4\\\\\n",
       "\tDatsun 710 & 22.8 & 4 & 108 &  93 & 3.85 & 2.320 & 18.61 & 1 & 1 & 4 & 1\\\\\n",
       "\tHornet 4 Drive & 21.4 & 6 & 258 & 110 & 3.08 & 3.215 & 19.44 & 1 & 0 & 3 & 1\\\\\n",
       "\tHornet Sportabout & 18.7 & 8 & 360 & 175 & 3.15 & 3.440 & 17.02 & 0 & 0 & 3 & 2\\\\\n",
       "\tValiant & 18.1 & 6 & 225 & 105 & 2.76 & 3.460 & 20.22 & 1 & 0 & 3 & 1\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 11\n",
       "\n",
       "| <!--/--> | mpg &lt;dbl&gt; | cyl &lt;dbl&gt; | disp &lt;dbl&gt; | hp &lt;dbl&gt; | drat &lt;dbl&gt; | wt &lt;dbl&gt; | qsec &lt;dbl&gt; | vs &lt;dbl&gt; | am &lt;dbl&gt; | gear &lt;dbl&gt; | carb &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| Mazda RX4 | 21.0 | 6 | 160 | 110 | 3.90 | 2.620 | 16.46 | 0 | 1 | 4 | 4 |\n",
       "| Mazda RX4 Wag | 21.0 | 6 | 160 | 110 | 3.90 | 2.875 | 17.02 | 0 | 1 | 4 | 4 |\n",
       "| Datsun 710 | 22.8 | 4 | 108 |  93 | 3.85 | 2.320 | 18.61 | 1 | 1 | 4 | 1 |\n",
       "| Hornet 4 Drive | 21.4 | 6 | 258 | 110 | 3.08 | 3.215 | 19.44 | 1 | 0 | 3 | 1 |\n",
       "| Hornet Sportabout | 18.7 | 8 | 360 | 175 | 3.15 | 3.440 | 17.02 | 0 | 0 | 3 | 2 |\n",
       "| Valiant | 18.1 | 6 | 225 | 105 | 2.76 | 3.460 | 20.22 | 1 | 0 | 3 | 1 |\n",
       "\n"
      ],
      "text/plain": [
       "                  mpg  cyl disp hp  drat wt    qsec  vs am gear carb\n",
       "Mazda RX4         21.0 6   160  110 3.90 2.620 16.46 0  1  4    4   \n",
       "Mazda RX4 Wag     21.0 6   160  110 3.90 2.875 17.02 0  1  4    4   \n",
       "Datsun 710        22.8 4   108   93 3.85 2.320 18.61 1  1  4    1   \n",
       "Hornet 4 Drive    21.4 6   258  110 3.08 3.215 19.44 1  0  3    1   \n",
       "Hornet Sportabout 18.7 8   360  175 3.15 3.440 17.02 0  0  3    2   \n",
       "Valiant           18.1 6   225  105 2.76 3.460 20.22 1  0  3    1   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A matrix: 6 × 10 of type dbl</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>mpg</th><th scope=col>cyl</th><th scope=col>disp</th><th scope=col>hp</th><th scope=col>drat</th><th scope=col>wt</th><th scope=col>qsec</th><th scope=col>vs</th><th scope=col>gear</th><th scope=col>carb</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>Mazda RX4</th><td>21.0</td><td>6</td><td>160</td><td>110</td><td>3.90</td><td>2.620</td><td>16.46</td><td>0</td><td>4</td><td>4</td></tr>\n",
       "\t<tr><th scope=row>Mazda RX4 Wag</th><td>21.0</td><td>6</td><td>160</td><td>110</td><td>3.90</td><td>2.875</td><td>17.02</td><td>0</td><td>4</td><td>4</td></tr>\n",
       "\t<tr><th scope=row>Datsun 710</th><td>22.8</td><td>4</td><td>108</td><td> 93</td><td>3.85</td><td>2.320</td><td>18.61</td><td>1</td><td>4</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>Hornet 4 Drive</th><td>21.4</td><td>6</td><td>258</td><td>110</td><td>3.08</td><td>3.215</td><td>19.44</td><td>1</td><td>3</td><td>1</td></tr>\n",
       "\t<tr><th scope=row>Hornet Sportabout</th><td>18.7</td><td>8</td><td>360</td><td>175</td><td>3.15</td><td>3.440</td><td>17.02</td><td>0</td><td>3</td><td>2</td></tr>\n",
       "\t<tr><th scope=row>Valiant</th><td>18.1</td><td>6</td><td>225</td><td>105</td><td>2.76</td><td>3.460</td><td>20.22</td><td>1</td><td>3</td><td>1</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 6 × 10 of type dbl\n",
       "\\begin{tabular}{r|llllllllll}\n",
       "  & mpg & cyl & disp & hp & drat & wt & qsec & vs & gear & carb\\\\\n",
       "\\hline\n",
       "\tMazda RX4 & 21.0 & 6 & 160 & 110 & 3.90 & 2.620 & 16.46 & 0 & 4 & 4\\\\\n",
       "\tMazda RX4 Wag & 21.0 & 6 & 160 & 110 & 3.90 & 2.875 & 17.02 & 0 & 4 & 4\\\\\n",
       "\tDatsun 710 & 22.8 & 4 & 108 &  93 & 3.85 & 2.320 & 18.61 & 1 & 4 & 1\\\\\n",
       "\tHornet 4 Drive & 21.4 & 6 & 258 & 110 & 3.08 & 3.215 & 19.44 & 1 & 3 & 1\\\\\n",
       "\tHornet Sportabout & 18.7 & 8 & 360 & 175 & 3.15 & 3.440 & 17.02 & 0 & 3 & 2\\\\\n",
       "\tValiant & 18.1 & 6 & 225 & 105 & 2.76 & 3.460 & 20.22 & 1 & 3 & 1\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 6 × 10 of type dbl\n",
       "\n",
       "| <!--/--> | mpg | cyl | disp | hp | drat | wt | qsec | vs | gear | carb |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| Mazda RX4 | 21.0 | 6 | 160 | 110 | 3.90 | 2.620 | 16.46 | 0 | 4 | 4 |\n",
       "| Mazda RX4 Wag | 21.0 | 6 | 160 | 110 | 3.90 | 2.875 | 17.02 | 0 | 4 | 4 |\n",
       "| Datsun 710 | 22.8 | 4 | 108 |  93 | 3.85 | 2.320 | 18.61 | 1 | 4 | 1 |\n",
       "| Hornet 4 Drive | 21.4 | 6 | 258 | 110 | 3.08 | 3.215 | 19.44 | 1 | 3 | 1 |\n",
       "| Hornet Sportabout | 18.7 | 8 | 360 | 175 | 3.15 | 3.440 | 17.02 | 0 | 3 | 2 |\n",
       "| Valiant | 18.1 | 6 | 225 | 105 | 2.76 | 3.460 | 20.22 | 1 | 3 | 1 |\n",
       "\n"
      ],
      "text/plain": [
       "                  mpg  cyl disp hp  drat wt    qsec  vs gear carb\n",
       "Mazda RX4         21.0 6   160  110 3.90 2.620 16.46 0  4    4   \n",
       "Mazda RX4 Wag     21.0 6   160  110 3.90 2.875 17.02 0  4    4   \n",
       "Datsun 710        22.8 4   108   93 3.85 2.320 18.61 1  4    1   \n",
       "Hornet 4 Drive    21.4 6   258  110 3.08 3.215 19.44 1  3    1   \n",
       "Hornet Sportabout 18.7 8   360  175 3.15 3.440 17.02 0  3    2   \n",
       "Valiant           18.1 6   225  105 2.76 3.460 20.22 1  3    1   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A matrix: 10 × 32 of type dbl</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>Mazda RX4</th><th scope=col>Mazda RX4 Wag</th><th scope=col>Datsun 710</th><th scope=col>Hornet 4 Drive</th><th scope=col>Hornet Sportabout</th><th scope=col>Valiant</th><th scope=col>Duster 360</th><th scope=col>Merc 240D</th><th scope=col>Merc 230</th><th scope=col>Merc 280</th><th scope=col>⋯</th><th scope=col>AMC Javelin</th><th scope=col>Camaro Z28</th><th scope=col>Pontiac Firebird</th><th scope=col>Fiat X1-9</th><th scope=col>Porsche 914-2</th><th scope=col>Lotus Europa</th><th scope=col>Ford Pantera L</th><th scope=col>Ferrari Dino</th><th scope=col>Maserati Bora</th><th scope=col>Volvo 142E</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>mpg</th><td> 21.00</td><td> 21.000</td><td> 22.80</td><td> 21.400</td><td> 18.70</td><td> 18.10</td><td> 14.30</td><td> 24.40</td><td> 22.80</td><td> 19.20</td><td>⋯</td><td> 15.200</td><td> 13.30</td><td> 19.200</td><td>27.300</td><td> 26.00</td><td> 30.400</td><td> 15.80</td><td> 19.70</td><td> 15.00</td><td> 21.40</td></tr>\n",
       "\t<tr><th scope=row>cyl</th><td>  6.00</td><td>  6.000</td><td>  4.00</td><td>  6.000</td><td>  8.00</td><td>  6.00</td><td>  8.00</td><td>  4.00</td><td>  4.00</td><td>  6.00</td><td>⋯</td><td>  8.000</td><td>  8.00</td><td>  8.000</td><td> 4.000</td><td>  4.00</td><td>  4.000</td><td>  8.00</td><td>  6.00</td><td>  8.00</td><td>  4.00</td></tr>\n",
       "\t<tr><th scope=row>disp</th><td>160.00</td><td>160.000</td><td>108.00</td><td>258.000</td><td>360.00</td><td>225.00</td><td>360.00</td><td>146.70</td><td>140.80</td><td>167.60</td><td>⋯</td><td>304.000</td><td>350.00</td><td>400.000</td><td>79.000</td><td>120.30</td><td> 95.100</td><td>351.00</td><td>145.00</td><td>301.00</td><td>121.00</td></tr>\n",
       "\t<tr><th scope=row>hp</th><td>110.00</td><td>110.000</td><td> 93.00</td><td>110.000</td><td>175.00</td><td>105.00</td><td>245.00</td><td> 62.00</td><td> 95.00</td><td>123.00</td><td>⋯</td><td>150.000</td><td>245.00</td><td>175.000</td><td>66.000</td><td> 91.00</td><td>113.000</td><td>264.00</td><td>175.00</td><td>335.00</td><td>109.00</td></tr>\n",
       "\t<tr><th scope=row>drat</th><td>  3.90</td><td>  3.900</td><td>  3.85</td><td>  3.080</td><td>  3.15</td><td>  2.76</td><td>  3.21</td><td>  3.69</td><td>  3.92</td><td>  3.92</td><td>⋯</td><td>  3.150</td><td>  3.73</td><td>  3.080</td><td> 4.080</td><td>  4.43</td><td>  3.770</td><td>  4.22</td><td>  3.62</td><td>  3.54</td><td>  4.11</td></tr>\n",
       "\t<tr><th scope=row>wt</th><td>  2.62</td><td>  2.875</td><td>  2.32</td><td>  3.215</td><td>  3.44</td><td>  3.46</td><td>  3.57</td><td>  3.19</td><td>  3.15</td><td>  3.44</td><td>⋯</td><td>  3.435</td><td>  3.84</td><td>  3.845</td><td> 1.935</td><td>  2.14</td><td>  1.513</td><td>  3.17</td><td>  2.77</td><td>  3.57</td><td>  2.78</td></tr>\n",
       "\t<tr><th scope=row>qsec</th><td> 16.46</td><td> 17.020</td><td> 18.61</td><td> 19.440</td><td> 17.02</td><td> 20.22</td><td> 15.84</td><td> 20.00</td><td> 22.90</td><td> 18.30</td><td>⋯</td><td> 17.300</td><td> 15.41</td><td> 17.050</td><td>18.900</td><td> 16.70</td><td> 16.900</td><td> 14.50</td><td> 15.50</td><td> 14.60</td><td> 18.60</td></tr>\n",
       "\t<tr><th scope=row>vs</th><td>  0.00</td><td>  0.000</td><td>  1.00</td><td>  1.000</td><td>  0.00</td><td>  1.00</td><td>  0.00</td><td>  1.00</td><td>  1.00</td><td>  1.00</td><td>⋯</td><td>  0.000</td><td>  0.00</td><td>  0.000</td><td> 1.000</td><td>  0.00</td><td>  1.000</td><td>  0.00</td><td>  0.00</td><td>  0.00</td><td>  1.00</td></tr>\n",
       "\t<tr><th scope=row>gear</th><td>  4.00</td><td>  4.000</td><td>  4.00</td><td>  3.000</td><td>  3.00</td><td>  3.00</td><td>  3.00</td><td>  4.00</td><td>  4.00</td><td>  4.00</td><td>⋯</td><td>  3.000</td><td>  3.00</td><td>  3.000</td><td> 4.000</td><td>  5.00</td><td>  5.000</td><td>  5.00</td><td>  5.00</td><td>  5.00</td><td>  4.00</td></tr>\n",
       "\t<tr><th scope=row>carb</th><td>  4.00</td><td>  4.000</td><td>  1.00</td><td>  1.000</td><td>  2.00</td><td>  1.00</td><td>  4.00</td><td>  2.00</td><td>  2.00</td><td>  4.00</td><td>⋯</td><td>  2.000</td><td>  4.00</td><td>  2.000</td><td> 1.000</td><td>  2.00</td><td>  2.000</td><td>  4.00</td><td>  6.00</td><td>  8.00</td><td>  2.00</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 10 × 32 of type dbl\n",
       "\\begin{tabular}{r|llllllllllllllllllllllllllllllll}\n",
       "  & Mazda RX4 & Mazda RX4 Wag & Datsun 710 & Hornet 4 Drive & Hornet Sportabout & Valiant & Duster 360 & Merc 240D & Merc 230 & Merc 280 & Merc 280C & Merc 450SE & Merc 450SL & Merc 450SLC & Cadillac Fleetwood & Lincoln Continental & Chrysler Imperial & Fiat 128 & Honda Civic & Toyota Corolla & Toyota Corona & Dodge Challenger & AMC Javelin & Camaro Z28 & Pontiac Firebird & Fiat X1-9 & Porsche 914-2 & Lotus Europa & Ford Pantera L & Ferrari Dino & Maserati Bora & Volvo 142E\\\\\n",
       "\\hline\n",
       "\tmpg &  21.00 &  21.000 &  22.80 &  21.400 &  18.70 &  18.10 &  14.30 &  24.40 &  22.80 &  19.20 &  17.80 &  16.40 &  17.30 &  15.20 &  10.40 &  10.400 &  14.700 & 32.40 & 30.400 & 33.900 &  21.500 &  15.50 &  15.200 &  13.30 &  19.200 & 27.300 &  26.00 &  30.400 &  15.80 &  19.70 &  15.00 &  21.40\\\\\n",
       "\tcyl &   6.00 &   6.000 &   4.00 &   6.000 &   8.00 &   6.00 &   8.00 &   4.00 &   4.00 &   6.00 &   6.00 &   8.00 &   8.00 &   8.00 &   8.00 &   8.000 &   8.000 &  4.00 &  4.000 &  4.000 &   4.000 &   8.00 &   8.000 &   8.00 &   8.000 &  4.000 &   4.00 &   4.000 &   8.00 &   6.00 &   8.00 &   4.00\\\\\n",
       "\tdisp & 160.00 & 160.000 & 108.00 & 258.000 & 360.00 & 225.00 & 360.00 & 146.70 & 140.80 & 167.60 & 167.60 & 275.80 & 275.80 & 275.80 & 472.00 & 460.000 & 440.000 & 78.70 & 75.700 & 71.100 & 120.100 & 318.00 & 304.000 & 350.00 & 400.000 & 79.000 & 120.30 &  95.100 & 351.00 & 145.00 & 301.00 & 121.00\\\\\n",
       "\thp & 110.00 & 110.000 &  93.00 & 110.000 & 175.00 & 105.00 & 245.00 &  62.00 &  95.00 & 123.00 & 123.00 & 180.00 & 180.00 & 180.00 & 205.00 & 215.000 & 230.000 & 66.00 & 52.000 & 65.000 &  97.000 & 150.00 & 150.000 & 245.00 & 175.000 & 66.000 &  91.00 & 113.000 & 264.00 & 175.00 & 335.00 & 109.00\\\\\n",
       "\tdrat &   3.90 &   3.900 &   3.85 &   3.080 &   3.15 &   2.76 &   3.21 &   3.69 &   3.92 &   3.92 &   3.92 &   3.07 &   3.07 &   3.07 &   2.93 &   3.000 &   3.230 &  4.08 &  4.930 &  4.220 &   3.700 &   2.76 &   3.150 &   3.73 &   3.080 &  4.080 &   4.43 &   3.770 &   4.22 &   3.62 &   3.54 &   4.11\\\\\n",
       "\twt &   2.62 &   2.875 &   2.32 &   3.215 &   3.44 &   3.46 &   3.57 &   3.19 &   3.15 &   3.44 &   3.44 &   4.07 &   3.73 &   3.78 &   5.25 &   5.424 &   5.345 &  2.20 &  1.615 &  1.835 &   2.465 &   3.52 &   3.435 &   3.84 &   3.845 &  1.935 &   2.14 &   1.513 &   3.17 &   2.77 &   3.57 &   2.78\\\\\n",
       "\tqsec &  16.46 &  17.020 &  18.61 &  19.440 &  17.02 &  20.22 &  15.84 &  20.00 &  22.90 &  18.30 &  18.90 &  17.40 &  17.60 &  18.00 &  17.98 &  17.820 &  17.420 & 19.47 & 18.520 & 19.900 &  20.010 &  16.87 &  17.300 &  15.41 &  17.050 & 18.900 &  16.70 &  16.900 &  14.50 &  15.50 &  14.60 &  18.60\\\\\n",
       "\tvs &   0.00 &   0.000 &   1.00 &   1.000 &   0.00 &   1.00 &   0.00 &   1.00 &   1.00 &   1.00 &   1.00 &   0.00 &   0.00 &   0.00 &   0.00 &   0.000 &   0.000 &  1.00 &  1.000 &  1.000 &   1.000 &   0.00 &   0.000 &   0.00 &   0.000 &  1.000 &   0.00 &   1.000 &   0.00 &   0.00 &   0.00 &   1.00\\\\\n",
       "\tgear &   4.00 &   4.000 &   4.00 &   3.000 &   3.00 &   3.00 &   3.00 &   4.00 &   4.00 &   4.00 &   4.00 &   3.00 &   3.00 &   3.00 &   3.00 &   3.000 &   3.000 &  4.00 &  4.000 &  4.000 &   3.000 &   3.00 &   3.000 &   3.00 &   3.000 &  4.000 &   5.00 &   5.000 &   5.00 &   5.00 &   5.00 &   4.00\\\\\n",
       "\tcarb &   4.00 &   4.000 &   1.00 &   1.000 &   2.00 &   1.00 &   4.00 &   2.00 &   2.00 &   4.00 &   4.00 &   3.00 &   3.00 &   3.00 &   4.00 &   4.000 &   4.000 &  1.00 &  2.000 &  1.000 &   1.000 &   2.00 &   2.000 &   4.00 &   2.000 &  1.000 &   2.00 &   2.000 &   4.00 &   6.00 &   8.00 &   2.00\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 10 × 32 of type dbl\n",
       "\n",
       "| <!--/--> | Mazda RX4 | Mazda RX4 Wag | Datsun 710 | Hornet 4 Drive | Hornet Sportabout | Valiant | Duster 360 | Merc 240D | Merc 230 | Merc 280 | ⋯ | AMC Javelin | Camaro Z28 | Pontiac Firebird | Fiat X1-9 | Porsche 914-2 | Lotus Europa | Ford Pantera L | Ferrari Dino | Maserati Bora | Volvo 142E |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| mpg |  21.00 |  21.000 |  22.80 |  21.400 |  18.70 |  18.10 |  14.30 |  24.40 |  22.80 |  19.20 | ⋯ |  15.200 |  13.30 |  19.200 | 27.300 |  26.00 |  30.400 |  15.80 |  19.70 |  15.00 |  21.40 |\n",
       "| cyl |   6.00 |   6.000 |   4.00 |   6.000 |   8.00 |   6.00 |   8.00 |   4.00 |   4.00 |   6.00 | ⋯ |   8.000 |   8.00 |   8.000 |  4.000 |   4.00 |   4.000 |   8.00 |   6.00 |   8.00 |   4.00 |\n",
       "| disp | 160.00 | 160.000 | 108.00 | 258.000 | 360.00 | 225.00 | 360.00 | 146.70 | 140.80 | 167.60 | ⋯ | 304.000 | 350.00 | 400.000 | 79.000 | 120.30 |  95.100 | 351.00 | 145.00 | 301.00 | 121.00 |\n",
       "| hp | 110.00 | 110.000 |  93.00 | 110.000 | 175.00 | 105.00 | 245.00 |  62.00 |  95.00 | 123.00 | ⋯ | 150.000 | 245.00 | 175.000 | 66.000 |  91.00 | 113.000 | 264.00 | 175.00 | 335.00 | 109.00 |\n",
       "| drat |   3.90 |   3.900 |   3.85 |   3.080 |   3.15 |   2.76 |   3.21 |   3.69 |   3.92 |   3.92 | ⋯ |   3.150 |   3.73 |   3.080 |  4.080 |   4.43 |   3.770 |   4.22 |   3.62 |   3.54 |   4.11 |\n",
       "| wt |   2.62 |   2.875 |   2.32 |   3.215 |   3.44 |   3.46 |   3.57 |   3.19 |   3.15 |   3.44 | ⋯ |   3.435 |   3.84 |   3.845 |  1.935 |   2.14 |   1.513 |   3.17 |   2.77 |   3.57 |   2.78 |\n",
       "| qsec |  16.46 |  17.020 |  18.61 |  19.440 |  17.02 |  20.22 |  15.84 |  20.00 |  22.90 |  18.30 | ⋯ |  17.300 |  15.41 |  17.050 | 18.900 |  16.70 |  16.900 |  14.50 |  15.50 |  14.60 |  18.60 |\n",
       "| vs |   0.00 |   0.000 |   1.00 |   1.000 |   0.00 |   1.00 |   0.00 |   1.00 |   1.00 |   1.00 | ⋯ |   0.000 |   0.00 |   0.000 |  1.000 |   0.00 |   1.000 |   0.00 |   0.00 |   0.00 |   1.00 |\n",
       "| gear |   4.00 |   4.000 |   4.00 |   3.000 |   3.00 |   3.00 |   3.00 |   4.00 |   4.00 |   4.00 | ⋯ |   3.000 |   3.00 |   3.000 |  4.000 |   5.00 |   5.000 |   5.00 |   5.00 |   5.00 |   4.00 |\n",
       "| carb |   4.00 |   4.000 |   1.00 |   1.000 |   2.00 |   1.00 |   4.00 |   2.00 |   2.00 |   4.00 | ⋯ |   2.000 |   4.00 |   2.000 |  1.000 |   2.00 |   2.000 |   4.00 |   6.00 |   8.00 |   2.00 |\n",
       "\n"
      ],
      "text/plain": [
       "     Mazda RX4 Mazda RX4 Wag Datsun 710 Hornet 4 Drive Hornet Sportabout\n",
       "mpg   21.00     21.000        22.80      21.400         18.70           \n",
       "cyl    6.00      6.000         4.00       6.000          8.00           \n",
       "disp 160.00    160.000       108.00     258.000        360.00           \n",
       "hp   110.00    110.000        93.00     110.000        175.00           \n",
       "drat   3.90      3.900         3.85       3.080          3.15           \n",
       "wt     2.62      2.875         2.32       3.215          3.44           \n",
       "qsec  16.46     17.020        18.61      19.440         17.02           \n",
       "vs     0.00      0.000         1.00       1.000          0.00           \n",
       "gear   4.00      4.000         4.00       3.000          3.00           \n",
       "carb   4.00      4.000         1.00       1.000          2.00           \n",
       "     Valiant Duster 360 Merc 240D Merc 230 Merc 280 ⋯ AMC Javelin Camaro Z28\n",
       "mpg   18.10   14.30      24.40     22.80    19.20   ⋯  15.200      13.30    \n",
       "cyl    6.00    8.00       4.00      4.00     6.00   ⋯   8.000       8.00    \n",
       "disp 225.00  360.00     146.70    140.80   167.60   ⋯ 304.000     350.00    \n",
       "hp   105.00  245.00      62.00     95.00   123.00   ⋯ 150.000     245.00    \n",
       "drat   2.76    3.21       3.69      3.92     3.92   ⋯   3.150       3.73    \n",
       "wt     3.46    3.57       3.19      3.15     3.44   ⋯   3.435       3.84    \n",
       "qsec  20.22   15.84      20.00     22.90    18.30   ⋯  17.300      15.41    \n",
       "vs     1.00    0.00       1.00      1.00     1.00   ⋯   0.000       0.00    \n",
       "gear   3.00    3.00       4.00      4.00     4.00   ⋯   3.000       3.00    \n",
       "carb   1.00    4.00       2.00      2.00     4.00   ⋯   2.000       4.00    \n",
       "     Pontiac Firebird Fiat X1-9 Porsche 914-2 Lotus Europa Ford Pantera L\n",
       "mpg   19.200          27.300     26.00         30.400       15.80        \n",
       "cyl    8.000           4.000      4.00          4.000        8.00        \n",
       "disp 400.000          79.000    120.30         95.100      351.00        \n",
       "hp   175.000          66.000     91.00        113.000      264.00        \n",
       "drat   3.080           4.080      4.43          3.770        4.22        \n",
       "wt     3.845           1.935      2.14          1.513        3.17        \n",
       "qsec  17.050          18.900     16.70         16.900       14.50        \n",
       "vs     0.000           1.000      0.00          1.000        0.00        \n",
       "gear   3.000           4.000      5.00          5.000        5.00        \n",
       "carb   2.000           1.000      2.00          2.000        4.00        \n",
       "     Ferrari Dino Maserati Bora Volvo 142E\n",
       "mpg   19.70        15.00         21.40    \n",
       "cyl    6.00         8.00          4.00    \n",
       "disp 145.00       301.00        121.00    \n",
       "hp   175.00       335.00        109.00    \n",
       "drat   3.62         3.54          4.11    \n",
       "wt     2.77         3.57          2.78    \n",
       "qsec  15.50        14.60         18.60    \n",
       "vs     0.00         0.00          1.00    \n",
       "gear   5.00         5.00          4.00    \n",
       "carb   6.00         8.00          2.00    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#First, we create the data to train the neural network.\n",
    "\n",
    "# predictor variables\n",
    "#X <- matrix(c(\n",
    "#  0,0,1,\n",
    "#  0,1,1,\n",
    "#  1,0,1,\n",
    "#  1,1,1\n",
    "#), ncol = 3, byrow = TRUE )\n",
    "\n",
    "head(mtcars)\n",
    "\n",
    "X<-as.matrix(mtcars[-c(9)])\n",
    "\n",
    "head(X)\n",
    "\n",
    "X<-t(X)\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# observed outcomes\n",
    "#y <- c(0, 1, 1, 0)\n",
    "\n",
    "y<-as.numeric(mtcars[['am']])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in nn$layer1 %*% nn$weights2: non-conformable arguments\n",
     "output_type": "error",
     "traceback": [
      "Error in nn$layer1 %*% nn$weights2: non-conformable arguments\nTraceback:\n",
      "1. NeuralNetwork(X, y, num_nodes = 4, num_iter = 1000)",
      "2. GD(nnet, num_iter)   # at line 18 of file <text>",
      "3. feedforward(nnet)   # at line 10 of file <text>",
      "4. sigmoid(nn$layer1 %*% nn$weights2)   # at line 6 of file <text>"
     ]
    }
   ],
   "source": [
    "nn <- NeuralNetwork(X,y,num_nodes=4, num_iter=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.frame: 4 × 2</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>Predicted</th><th scope=col>Actual</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>0.031</td><td>0</td></tr>\n",
       "\t<tr><td>0.973</td><td>1</td></tr>\n",
       "\t<tr><td>0.970</td><td>1</td></tr>\n",
       "\t<tr><td>0.031</td><td>0</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 4 × 2\n",
       "\\begin{tabular}{r|ll}\n",
       " Predicted & Actual\\\\\n",
       " <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t 0.031 & 0\\\\\n",
       "\t 0.973 & 1\\\\\n",
       "\t 0.970 & 1\\\\\n",
       "\t 0.031 & 0\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 4 × 2\n",
       "\n",
       "| Predicted &lt;dbl&gt; | Actual &lt;dbl&gt; |\n",
       "|---|---|\n",
       "| 0.031 | 0 |\n",
       "| 0.973 | 1 |\n",
       "| 0.970 | 1 |\n",
       "| 0.031 | 0 |\n",
       "\n"
      ],
      "text/plain": [
       "  Predicted Actual\n",
       "1 0.031     0     \n",
       "2 0.973     1     \n",
       "3 0.970     1     \n",
       "4 0.031     0     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.frame: 6 × 2</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>iteration</th><th scope=col>loss</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>2</td><td>1.2958936</td></tr>\n",
       "\t<tr><td>3</td><td>1.0396034</td></tr>\n",
       "\t<tr><td>4</td><td>0.9981807</td></tr>\n",
       "\t<tr><td>5</td><td>0.9979379</td></tr>\n",
       "\t<tr><td>6</td><td>0.9977155</td></tr>\n",
       "\t<tr><td>7</td><td>0.9974873</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 2\n",
       "\\begin{tabular}{r|ll}\n",
       " iteration & loss\\\\\n",
       " <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t 2 & 1.2958936\\\\\n",
       "\t 3 & 1.0396034\\\\\n",
       "\t 4 & 0.9981807\\\\\n",
       "\t 5 & 0.9979379\\\\\n",
       "\t 6 & 0.9977155\\\\\n",
       "\t 7 & 0.9974873\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 2\n",
       "\n",
       "| iteration &lt;dbl&gt; | loss &lt;dbl&gt; |\n",
       "|---|---|\n",
       "| 2 | 1.2958936 |\n",
       "| 3 | 1.0396034 |\n",
       "| 4 | 0.9981807 |\n",
       "| 5 | 0.9979379 |\n",
       "| 6 | 0.9977155 |\n",
       "| 7 | 0.9974873 |\n",
       "\n"
      ],
      "text/plain": [
       "  iteration loss     \n",
       "1 2         1.2958936\n",
       "2 3         1.0396034\n",
       "3 4         0.9981807\n",
       "4 5         0.9979379\n",
       "5 6         0.9977155\n",
       "6 7         0.9974873"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.frame: 6 × 2</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>iteration</th><th scope=col>loss</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>995</th><td> 996</td><td>0.003583922</td></tr>\n",
       "\t<tr><th scope=row>996</th><td> 997</td><td>0.003578728</td></tr>\n",
       "\t<tr><th scope=row>997</th><td> 998</td><td>0.003573549</td></tr>\n",
       "\t<tr><th scope=row>998</th><td> 999</td><td>0.003568383</td></tr>\n",
       "\t<tr><th scope=row>999</th><td>1000</td><td>0.003563232</td></tr>\n",
       "\t<tr><th scope=row>1000</th><td>1001</td><td>0.003558095</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 2\n",
       "\\begin{tabular}{r|ll}\n",
       "  & iteration & loss\\\\\n",
       "  & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t995 &  996 & 0.003583922\\\\\n",
       "\t996 &  997 & 0.003578728\\\\\n",
       "\t997 &  998 & 0.003573549\\\\\n",
       "\t998 &  999 & 0.003568383\\\\\n",
       "\t999 & 1000 & 0.003563232\\\\\n",
       "\t1000 & 1001 & 0.003558095\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 2\n",
       "\n",
       "| <!--/--> | iteration &lt;dbl&gt; | loss &lt;dbl&gt; |\n",
       "|---|---|---|\n",
       "| 995 |  996 | 0.003583922 |\n",
       "| 996 |  997 | 0.003578728 |\n",
       "| 997 |  998 | 0.003573549 |\n",
       "| 998 |  999 | 0.003568383 |\n",
       "| 999 | 1000 | 0.003563232 |\n",
       "| 1000 | 1001 | 0.003558095 |\n",
       "\n"
      ],
      "text/plain": [
       "     iteration loss       \n",
       "995   996      0.003583922\n",
       "996   997      0.003578728\n",
       "997   998      0.003573549\n",
       "998   999      0.003568383\n",
       "999  1000      0.003563232\n",
       "1000 1001      0.003558095"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nn$yhat\n",
    "head(nn$loss)\n",
    "tail(nn$loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAIAAADytinCAAAABmJLR0QA/wD/AP+gvaeTAAAg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\nAKf+Py54DZU8l4Y2AAAAAElFTkSuQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 240,
       "width": 240
      },
      "text/plain": {
       "height": 240,
       "width": 240
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "options(repr.plot.width = 4, repr.plot.height = 4)\n",
    "\n",
    "# plot the cost\n",
    "library(ggplot2)\n",
    "\n",
    "ggplot(data = nn$loss, aes(x = iteration, y = loss)) +\n",
    "  geom_line()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
